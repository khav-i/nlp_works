{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Свёрточные нейросети и POS-теггинг\n","\n","POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T14:24:33.533563Z","iopub.status.busy":"2024-09-19T14:24:33.533244Z","iopub.status.idle":"2024-09-19T14:24:37.720567Z","shell.execute_reply":"2024-09-19T14:24:37.719386Z","shell.execute_reply.started":"2024-09-19T14:24:33.533496Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'stepik-dl-nlp'...\n","remote: Enumerating objects: 296, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 296 (delta 0), reused 1 (delta 0), pack-reused 293 (from 1)\u001b[K\n","Receiving objects: 100% (296/296), 42.30 MiB | 24.04 MiB/s, done.\n","Resolving deltas: 100% (134/134), done.\n"]}],"source":["!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git #  && pip install -r stepik-dl-nlp/requirements.txt -q\n","import sys; sys.path.append('./stepik-dl-nlp')"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:42:57.976431Z","start_time":"2019-10-29T19:42:57.959538Z"},"execution":{"iopub.execute_input":"2024-09-19T14:24:43.346231Z","iopub.status.busy":"2024-09-19T14:24:43.345850Z","iopub.status.idle":"2024-09-19T14:25:10.944633Z","shell.execute_reply":"2024-09-19T14:25:10.943397Z","shell.execute_reply.started":"2024-09-19T14:24:43.346193Z"},"trusted":true},"outputs":[],"source":["!pip install pyconll -q\n","!pip install spacy_udpipe -q"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:34.549739Z","start_time":"2019-10-29T19:49:32.179692Z"},"execution":{"iopub.execute_input":"2024-09-19T14:49:26.050310Z","iopub.status.busy":"2024-09-19T14:49:26.049896Z","iopub.status.idle":"2024-09-19T14:49:32.647156Z","shell.execute_reply":"2024-09-19T14:49:32.646353Z","shell.execute_reply.started":"2024-09-19T14:49:26.050274Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# import warnings\n","# warnings.filterwarnings('ignore')\n","\n","from sklearn.metrics import classification_report\n","\n","import numpy as np\n","\n","import pyconll\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import TensorDataset\n","\n","import dlnlputils\n","from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n","    character_tokenize, POSTagger\n","from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n","\n","init_random_seed()"]},{"cell_type":"markdown","metadata":{},"source":["## Загрузка текстов и разбиение на обучающую и тестовую подвыборки"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:08.433599Z","start_time":"2019-10-29T19:46:05.110693Z"},"execution":{"iopub.execute_input":"2024-09-19T14:49:50.361956Z","iopub.status.busy":"2024-09-19T14:49:50.361039Z","iopub.status.idle":"2024-09-19T14:49:55.222506Z","shell.execute_reply":"2024-09-19T14:49:55.221155Z","shell.execute_reply.started":"2024-09-19T14:49:50.361912Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-09-19 14:49:51--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 40736599 (39M) [application/octet-stream]\n","Saving to: './stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu'\n","\n","./stepik-dl-nlp/dat 100%[===================>]  38.85M   240MB/s    in 0.2s    \n","\n","2024-09-19 14:49:53 (240 MB/s) - './stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu' saved [40736599/40736599]\n","\n","--2024-09-19 14:49:54--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14704579 (14M) [application/octet-stream]\n","Saving to: './stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu'\n","\n","./stepik-dl-nlp/dat 100%[===================>]  14.02M  --.-KB/s    in 0.08s   \n","\n","2024-09-19 14:49:55 (180 MB/s) - './stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu' saved [14704579/14704579]\n","\n"]}],"source":["!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n","!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:56.525561Z","start_time":"2019-10-29T19:49:37.315213Z"},"execution":{"iopub.execute_input":"2024-09-19T14:51:04.481013Z","iopub.status.busy":"2024-09-19T14:51:04.480179Z","iopub.status.idle":"2024-09-19T14:51:20.303438Z","shell.execute_reply":"2024-09-19T14:51:20.302674Z","shell.execute_reply.started":"2024-09-19T14:51:04.480968Z"},"trusted":true},"outputs":[],"source":["full_train = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu')\n","full_test = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu')"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:56.548127Z","start_time":"2019-10-29T19:49:56.527559Z"},"execution":{"iopub.execute_input":"2024-09-19T14:51:58.507306Z","iopub.status.busy":"2024-09-19T14:51:58.506630Z","iopub.status.idle":"2024-09-19T14:51:58.554136Z","shell.execute_reply":"2024-09-19T14:51:58.553176Z","shell.execute_reply.started":"2024-09-19T14:51:58.507267Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Анкета NOUN\n",". PUNCT\n","\n","Начальник NOUN\n","областного ADJ\n","управления NOUN\n","связи NOUN\n","Семен PROPN\n","Еремеевич PROPN\n","был AUX\n","человек NOUN\n","простой ADJ\n",", PUNCT\n","приходил VERB\n","на ADP\n","работу NOUN\n","всегда ADV\n","вовремя ADV\n",", PUNCT\n","здоровался VERB\n","с ADP\n","секретаршей NOUN\n","за ADP\n","руку NOUN\n","и CCONJ\n","иногда ADV\n","даже PART\n","писал VERB\n","в ADP\n","стенгазету NOUN\n","заметки NOUN\n","под ADP\n","псевдонимом NOUN\n","\" PUNCT\n","Муха NOUN\n","\" PUNCT\n",". PUNCT\n","\n"]}],"source":["for sent in full_train[:2]:\n","    for token in sent:\n","        print(token.form, token.upos)\n","    print()"]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:56.916262Z","start_time":"2019-10-29T19:49:56.549806Z"},"execution":{"iopub.execute_input":"2024-09-19T14:53:24.063607Z","iopub.status.busy":"2024-09-19T14:53:24.062652Z","iopub.status.idle":"2024-09-19T14:53:24.287601Z","shell.execute_reply":"2024-09-19T14:53:24.286685Z","shell.execute_reply.started":"2024-09-19T14:53:24.063565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Наибольшая длина предложения 194\n","Наибольшая длина токена 31\n"]}],"source":["MAX_SENT_LEN = max(len(sent) for sent in full_train)\n","MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n","print('Наибольшая длина предложения', MAX_SENT_LEN)\n","print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:57.251433Z","start_time":"2019-10-29T19:49:56.919818Z"},"execution":{"iopub.execute_input":"2024-09-19T14:53:29.720852Z","iopub.status.busy":"2024-09-19T14:53:29.720427Z","iopub.status.idle":"2024-09-19T14:53:29.946781Z","shell.execute_reply":"2024-09-19T14:53:29.945835Z","shell.execute_reply.started":"2024-09-19T14:53:29.720815Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Анкета .\n","Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n","В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n","Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n","Приемная была обставлена просто , но по-деловому .\n","У двери стоял стол секретарши , на столе - пишущая машинка с широкой кареткой .\n","В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того , чтобы заглушать голос начальника , доносившийся из кабинета , так как , бесспорно , среди посетителей могли находиться и случайные люди .\n","Кабинет отличался скромностью , присущей Семену Еремеевичу .\n","В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла .\n","Справа был стол для заседаний - длинный , накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями .\n"]}],"source":["all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\n","print('\\n'.join(all_train_texts[:10]))"]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.124148Z","start_time":"2019-10-29T19:49:57.254191Z"},"execution":{"iopub.execute_input":"2024-09-19T14:53:34.000158Z","iopub.status.busy":"2024-09-19T14:53:33.999269Z","iopub.status.idle":"2024-09-19T14:53:34.492996Z","shell.execute_reply":"2024-09-19T14:53:34.492022Z","shell.execute_reply.started":"2024-09-19T14:53:34.000119Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество уникальных символов 142\n","[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\n"]}],"source":["train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\n","char_vocab, word_doc_freq = build_vocabulary(\n","    train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>'\n",")\n","print(\"Количество уникальных символов\", len(char_vocab))\n","print(list(char_vocab.items())[:10])"]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.524125Z","start_time":"2019-10-29T19:49:58.125577Z"},"execution":{"iopub.execute_input":"2024-09-19T14:53:38.890696Z","iopub.status.busy":"2024-09-19T14:53:38.890005Z","iopub.status.idle":"2024-09-19T14:53:39.088337Z","shell.execute_reply":"2024-09-19T14:53:39.087420Z","shell.execute_reply.started":"2024-09-19T14:53:38.890656Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'<NOTAG>': 0,\n"," 'ADJ': 1,\n"," 'ADP': 2,\n"," 'ADV': 3,\n"," 'AUX': 4,\n"," 'CCONJ': 5,\n"," 'DET': 6,\n"," 'INTJ': 7,\n"," 'NOUN': 8,\n"," 'NUM': 9,\n"," 'PART': 10,\n"," 'PRON': 11,\n"," 'PROPN': 12,\n"," 'PUNCT': 13,\n"," 'SCONJ': 14,\n"," 'SYM': 15,\n"," 'VERB': 16,\n"," 'X': 17}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\n","label2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\n","label2id"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-19T14:53:44.979113Z","iopub.status.busy":"2024-09-19T14:53:44.978722Z","iopub.status.idle":"2024-09-19T14:53:45.027169Z","shell.execute_reply":"2024-09-19T14:53:45.026291Z","shell.execute_reply.started":"2024-09-19T14:53:44.979073Z"},"trusted":true},"outputs":[],"source":["def pos_corpus_to_tensor(sentences, char2id, label2id, max_sent_len, max_token_len):\n","    inputs = torch.zeros((len(sentences), max_sent_len, max_token_len + 2), dtype=torch.long)\n","    targets = torch.zeros((len(sentences), max_sent_len), dtype=torch.long)\n","\n","    for sent_i, sent in enumerate(sentences):\n","#         for token_i, token in enumerate(sent):\n","#             targets[sent_i, token_i] = label2id.get(token.upos, 0)\n","#             for char_i, char in enumerate(token.form):\n","#                 inputs[sent_i, token_i, char_i + 1] = char2id.get(char, 0)    \n","        for token_i, token in enumerate(sent):\n","            targets[sent_i, token_i] = label2id.get(token.upos, 0)\n","            if token.form is not None:\n","                for char_i, char in enumerate(token.form):\n","                    inputs[sent_i, token_i, char_i + 1] = char2id.get(char, 0)\n","            else:\n","                print(f\"Warning: token {token} has no form at sentence {sent_i}, token {token_i}\")\n","\n","    return inputs, targets"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.752672Z","start_time":"2019-10-29T19:49:58.526431Z"},"execution":{"iopub.execute_input":"2024-09-19T14:54:19.260434Z","iopub.status.busy":"2024-09-19T14:54:19.259409Z","iopub.status.idle":"2024-09-19T14:54:51.290001Z","shell.execute_reply":"2024-09-19T14:54:51.289148Z","shell.execute_reply.started":"2024-09-19T14:54:19.260383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: token <pyconll.unit.token.Token object at 0x7fa4d39e9ec0> has no form at sentence 6587, token 23\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d38f11c0> has no form at sentence 6614, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d3701ac0> has no form at sentence 6661, token 14\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d3689840> has no form at sentence 6701, token 20\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d3359440> has no form at sentence 6772, token 21\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d2b70440> has no form at sentence 6950, token 7\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d2ab5940> has no form at sentence 6986, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d22ed4c0> has no form at sentence 7149, token 7\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d22eefc0> has no form at sentence 7152, token 12\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d23761c0> has no form at sentence 7161, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d22855c0> has no form at sentence 7185, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d2188340> has no form at sentence 7211, token 15\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d1ed28c0> has no form at sentence 7260, token 14\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d19f7f40> has no form at sentence 7435, token 16\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d1521740> has no form at sentence 7584, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d13885c0> has no form at sentence 7632, token 36\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d120cdc0> has no form at sentence 7645, token 32\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0f27dc0> has no form at sentence 7739, token 34\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0f27e40> has no form at sentence 7739, token 35\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0cccec0> has no form at sentence 7809, token 8\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0d4af40> has no form at sentence 7831, token 4\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0d4b240> has no form at sentence 7831, token 9\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0d4bbc0> has no form at sentence 7832, token 11\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0d7cc40> has no form at sentence 7834, token 9\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0d7e2c0> has no form at sentence 7838, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0bc7d40> has no form at sentence 7847, token 8\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0c073c0> has no form at sentence 7854, token 25\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0c49740> has no form at sentence 7857, token 26\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0c8dec0> has no form at sentence 7868, token 1\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0a10c40> has no form at sentence 7922, token 12\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0a10e40> has no form at sentence 7922, token 16\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0a2ccc0> has no form at sentence 7930, token 1\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0952940> has no form at sentence 7971, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0988040> has no form at sentence 7975, token 8\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d0840940> has no form at sentence 8015, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d06a9240> has no form at sentence 8094, token 7\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d06a93c0> has no form at sentence 8094, token 9\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d042a740> has no form at sentence 8134, token 3\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d042b340> has no form at sentence 8135, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d02d9b40> has no form at sentence 8152, token 37\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d038a3c0> has no form at sentence 8181, token 4\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d038ac40> has no form at sentence 8183, token 5\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d01c0dc0> has no form at sentence 8188, token 0\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d01c3c40> has no form at sentence 8194, token 21\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d01f3640> has no form at sentence 8201, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d00efdc0> has no form at sentence 8230, token 15\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cffcd6c0> has no form at sentence 8244, token 8\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cffcf440> has no form at sentence 8248, token 19\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4d000d840> has no form at sentence 8252, token 10\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cfec6840> has no form at sentence 8276, token 12\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cff4c8c0> has no form at sentence 8283, token 31\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cff4c940> has no form at sentence 8283, token 32\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cff87e40> has no form at sentence 8303, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cfe38fc0> has no form at sentence 8328, token 2\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf92e540> has no form at sentence 8511, token 6\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf96a7c0> has no form at sentence 8521, token 7\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf86f7c0> has no form at sentence 8555, token 9\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf8ac540> has no form at sentence 8557, token 6\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf75ed40> has no form at sentence 8587, token 8\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cf2ccb40> has no form at sentence 8715, token 16\n","Warning: token <pyconll.unit.token.Token object at 0x7fa4cef55c40> has no form at sentence 8874, token 11\n"]}],"source":["train_inputs, train_labels = pos_corpus_to_tensor(\n","    full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN\n",")\n","train_dataset = TensorDataset(train_inputs, train_labels)\n","\n","test_inputs, test_labels = pos_corpus_to_tensor(\n","    full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN\n",")\n","test_dataset = TensorDataset(test_inputs, test_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Вспомогательная свёрточная архитектура"]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.316516Z","start_time":"2019-10-29T19:46:17.539Z"},"execution":{"iopub.execute_input":"2024-09-19T14:55:15.732408Z","iopub.status.busy":"2024-09-19T14:55:15.731545Z","iopub.status.idle":"2024-09-19T14:55:15.781344Z","shell.execute_reply":"2024-09-19T14:55:15.780541Z","shell.execute_reply.started":"2024-09-19T14:55:15.732368Z"},"trusted":true},"outputs":[],"source":["class StackedConv1d(nn.Module):\n","    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0):\n","        super().__init__()\n","        layers = []\n","        for _ in range(layers_n):\n","            layers.append(nn.Sequential(\n","                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2),\n","                nn.Dropout(dropout),\n","                nn.LeakyReLU()))\n","        self.layers = nn.ModuleList(layers)\n","    \n","    def forward(self, x):\n","        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n","        for layer in self.layers:\n","            x = x + layer(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Предсказание частей речи на уровне отдельных токенов"]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.317452Z","start_time":"2019-10-29T19:46:23.135Z"},"execution":{"iopub.execute_input":"2024-09-19T14:55:23.864741Z","iopub.status.busy":"2024-09-19T14:55:23.864340Z","iopub.status.idle":"2024-09-19T14:55:23.914982Z","shell.execute_reply":"2024-09-19T14:55:23.914031Z","shell.execute_reply.started":"2024-09-19T14:55:23.864705Z"},"trusted":true},"outputs":[],"source":["class SingleTokenPOSTagger(nn.Module):\n","    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n","        super().__init__()\n","        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","        self.backbone = StackedConv1d(embedding_size, **kwargs)\n","        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","        self.out = nn.Linear(embedding_size, labels_num)\n","        self.labels_num = labels_num\n","    \n","    def forward(self, tokens):\n","        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n","        batch_size, max_sent_len, max_token_len = tokens.shape\n","        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n","        \n","        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","        \n","        features = self.backbone(char_embeddings)\n","        \n","        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","        \n","        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n","        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n","        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n","        return logits"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.318497Z","start_time":"2019-10-29T19:46:23.764Z"},"execution":{"iopub.execute_input":"2024-09-19T15:00:55.804103Z","iopub.status.busy":"2024-09-19T15:00:55.803092Z","iopub.status.idle":"2024-09-19T15:00:55.858344Z","shell.execute_reply":"2024-09-19T15:00:55.857264Z","shell.execute_reply.started":"2024-09-19T15:00:55.804059Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 47314\n"]}],"source":["single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3)\n","print('Количество параметров', sum(np.prod(t.shape) for t in single_token_model.parameters()))"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.319470Z","start_time":"2019-10-29T19:46:25.552Z"},"execution":{"iopub.execute_input":"2024-09-19T15:01:03.178378Z","iopub.status.busy":"2024-09-19T15:01:03.177657Z","iopub.status.idle":"2024-09-19T15:22:01.972345Z","shell.execute_reply":"2024-09-19T15:22:01.971409Z","shell.execute_reply.started":"2024-09-19T15:01:03.178338Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 384 итераций, 124.13 сек\n","Среднее значение функции потерь на обучении 0.0967952593685671\n","Среднее значение функции потерь на валидации 0.04547579009270314\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 384 итераций, 123.14 сек\n","Среднее значение функции потерь на обучении 0.031819634095882066\n","Среднее значение функции потерь на валидации 0.03435223191829011\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 384 итераций, 123.14 сек\n","Среднее значение функции потерь на обучении 0.02703603423045327\n","Среднее значение функции потерь на валидации 0.02799201244027308\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 384 итераций, 123.15 сек\n","Среднее значение функции потерь на обучении 0.024699799265363254\n","Среднее значение функции потерь на валидации 0.03271952832099235\n","\n","Эпоха 4\n","Эпоха: 384 итераций, 123.17 сек\n","Среднее значение функции потерь на обучении 0.023389001624309458\n","Среднее значение функции потерь на валидации 0.023861068466881123\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 384 итераций, 123.01 сек\n","Среднее значение функции потерь на обучении 0.022533608539864265\n","Среднее значение функции потерь на валидации 0.023713761682410052\n","Новая лучшая модель!\n","\n","Эпоха 6\n","Эпоха: 384 итераций, 123.09 сек\n","Среднее значение функции потерь на обучении 0.021262301782068487\n","Среднее значение функции потерь на валидации 0.024207600641368638\n","\n","Эпоха 7\n","Эпоха: 384 итераций, 123.02 сек\n","Среднее значение функции потерь на обучении 0.020723876863485202\n","Среднее значение функции потерь на валидации 0.022065181054617508\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 384 итераций, 123.07 сек\n","Среднее значение функции потерь на обучении 0.020499564195536852\n","Среднее значение функции потерь на валидации 0.023085437346212934\n","\n","Эпоха 9\n","Эпоха: 384 итераций, 123.12 сек\n","Среднее значение функции потерь на обучении 0.019989191481727175\n","Среднее значение функции потерь на валидации 0.022756875732378796\n","\n"]}],"source":["best_val_loss,best_single_token_model = train_eval_loop(\n","    single_token_model,\n","    train_dataset,\n","    test_dataset,\n","    F.cross_entropy,\n","    lr=5e-3,\n","    epoch_n=10,\n","    batch_size=64,\n","    device='cuda',\n","    early_stopping_patience=5,\n","    max_batches_per_epoch_train=500,\n","    max_batches_per_epoch_val=100,\n","    lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optim, patience=2, factor=0.5, verbose=True\n","    )\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.320568Z","start_time":"2019-10-29T19:46:47.579Z"},"execution":{"iopub.execute_input":"2024-09-19T15:24:34.486457Z","iopub.status.busy":"2024-09-19T15:24:34.485865Z","iopub.status.idle":"2024-09-19T15:24:34.545860Z","shell.execute_reply":"2024-09-19T15:24:34.544875Z","shell.execute_reply.started":"2024-09-19T15:24:34.486417Z"},"trusted":true},"outputs":[],"source":["torch.save(best_single_token_model.state_dict(), './stepik-dl-nlp/models/single_token_pos.pth')"]},{"cell_type":"code","execution_count":21,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.321566Z","start_time":"2019-10-29T19:46:47.731Z"},"execution":{"iopub.execute_input":"2024-09-19T15:29:12.593221Z","iopub.status.busy":"2024-09-19T15:29:12.592851Z","iopub.status.idle":"2024-09-19T15:29:12.654947Z","shell.execute_reply":"2024-09-19T15:29:12.654028Z","shell.execute_reply.started":"2024-09-19T15:29:12.593188Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["single_token_model.load_state_dict(torch.load('./stepik-dl-nlp/models/single_token_pos.pth', weights_only=True))"]},{"cell_type":"code","execution_count":22,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.324276Z","start_time":"2019-10-29T19:46:48.445Z"},"execution":{"iopub.execute_input":"2024-09-19T15:29:15.710495Z","iopub.status.busy":"2024-09-19T15:29:15.709712Z","iopub.status.idle":"2024-09-19T15:29:51.694035Z","shell.execute_reply":"2024-09-19T15:29:51.693216Z","shell.execute_reply.started":"2024-09-19T15:29:15.710455Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["767it [00:10, 71.90it/s]                             \n","/tmp/ipykernel_36/2011350103.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(train_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.019009562209248543\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   4330443\n","         ADJ       0.88      0.94      0.91     43357\n","         ADP       1.00      0.99      0.99     39344\n","         ADV       0.84      0.92      0.87     22733\n","         AUX       0.86      0.64      0.73      3537\n","       CCONJ       0.88      0.98      0.93     15168\n","         DET       0.78      0.88      0.83     10781\n","        INTJ       0.90      0.18      0.30        50\n","        NOUN       0.97      0.94      0.95    103538\n","         NUM       0.92      0.92      0.92      5640\n","        PART       0.96      0.79      0.86     13556\n","        PRON       0.90      0.82      0.86     18734\n","       PROPN       0.85      0.94      0.89     14854\n","       PUNCT       1.00      1.00      1.00     77972\n","       SCONJ       0.85      0.70      0.77      8057\n","         SYM       1.00      0.99      0.99       420\n","        VERB       0.93      0.94      0.93     47731\n","           X       0.99      0.59      0.74       189\n","\n","    accuracy                           0.99   4756104\n","   macro avg       0.92      0.84      0.86   4756104\n","weighted avg       0.99      0.99      0.99   4756104\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["279it [00:03, 75.87it/s]                              \n","/tmp/ipykernel_36/2011350103.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(test_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.024060752242803574\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1574439\n","         ADJ       0.85      0.93      0.88     15103\n","         ADP       1.00      0.99      0.99     13717\n","         ADV       0.80      0.90      0.85      7783\n","         AUX       0.87      0.57      0.69      1390\n","       CCONJ       0.89      0.98      0.93      5672\n","         DET       0.78      0.82      0.80      4265\n","        INTJ       1.00      0.21      0.34        24\n","        NOUN       0.96      0.93      0.94     36238\n","         NUM       0.85      0.86      0.86      1734\n","        PART       0.94      0.77      0.85      5125\n","        PRON       0.89      0.83      0.86      7444\n","       PROPN       0.81      0.89      0.85      5473\n","       PUNCT       1.00      1.00      1.00     29186\n","       SCONJ       0.83      0.64      0.72      2865\n","         SYM       1.00      0.89      0.94        62\n","        VERB       0.91      0.92      0.91     17110\n","           X       1.00      0.38      0.55       134\n","\n","    accuracy                           0.99   1727764\n","   macro avg       0.91      0.80      0.83   1727764\n","weighted avg       0.99      0.99      0.99   1727764\n","\n"]}],"source":["train_pred = predict_with_model(single_token_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(single_token_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]},{"cell_type":"markdown","metadata":{},"source":["## Предсказание частей речи на уровне предложений (с учётом контекста)"]},{"cell_type":"code","execution_count":24,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.325744Z","start_time":"2019-10-29T19:46:50.139Z"},"execution":{"iopub.execute_input":"2024-09-19T15:30:26.562671Z","iopub.status.busy":"2024-09-19T15:30:26.561906Z","iopub.status.idle":"2024-09-19T15:30:26.621173Z","shell.execute_reply":"2024-09-19T15:30:26.620259Z","shell.execute_reply.started":"2024-09-19T15:30:26.562632Z"},"trusted":true},"outputs":[],"source":["class SentenceLevelPOSTagger(nn.Module):\n","    def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n","        super().__init__()\n","        self.embedding_size = embedding_size\n","        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","        self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n","        self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n","        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","        self.out = nn.Conv1d(embedding_size, labels_num, 1)\n","        self.labels_num = labels_num\n","    \n","    def forward(self, tokens):\n","        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n","        batch_size, max_sent_len, max_token_len = tokens.shape\n","        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n","        \n","        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","        char_features = self.single_token_backbone(char_embeddings)\n","        \n","        token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","\n","        token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n","        token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n","        context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n","\n","        logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n","        return logits"]},{"cell_type":"code","execution_count":26,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.326925Z","start_time":"2019-10-29T19:46:50.310Z"},"execution":{"iopub.execute_input":"2024-09-19T15:30:49.023992Z","iopub.status.busy":"2024-09-19T15:30:49.023135Z","iopub.status.idle":"2024-09-19T15:30:49.083983Z","shell.execute_reply":"2024-09-19T15:30:49.083032Z","shell.execute_reply.started":"2024-09-19T15:30:49.023950Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 84370\n"]}],"source":["sentence_level_model = SentenceLevelPOSTagger(\n","    len(char_vocab), len(label2id), embedding_size=64,\n","    single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n","    context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3)\n",")\n","print('Количество параметров', sum(np.prod(t.shape) for t in sentence_level_model.parameters()))"]},{"cell_type":"code","execution_count":28,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.327888Z","start_time":"2019-10-29T19:46:50.737Z"},"execution":{"iopub.execute_input":"2024-09-19T15:31:50.025177Z","iopub.status.busy":"2024-09-19T15:31:50.024453Z","iopub.status.idle":"2024-09-19T15:53:05.325368Z","shell.execute_reply":"2024-09-19T15:53:05.324367Z","shell.execute_reply.started":"2024-09-19T15:31:50.025136Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 384 итераций, 124.95 сек\n","Среднее значение функции потерь на обучении 0.08527418516071823\n","Среднее значение функции потерь на валидации 0.03221062078408086\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 384 итераций, 124.90 сек\n","Среднее значение функции потерь на обучении 0.02868927546660416\n","Среднее значение функции потерь на валидации 0.022986181615160244\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 384 итераций, 124.89 сек\n","Среднее значение функции потерь на обучении 0.023221147204215715\n","Среднее значение функции потерь на валидации 0.020432450568838283\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 384 итераций, 124.89 сек\n","Среднее значение функции потерь на обучении 0.020532036964141298\n","Среднее значение функции потерь на валидации 0.017697710820501394\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 384 итераций, 124.90 сек\n","Среднее значение функции потерь на обучении 0.019164517885656096\n","Среднее значение функции потерь на валидации 0.01706834639062976\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 384 итераций, 124.92 сек\n","Среднее значение функции потерь на обучении 0.0179654567449082\n","Среднее значение функции потерь на валидации 0.015728972289748122\n","Новая лучшая модель!\n","\n","Эпоха 6\n","Эпоха: 384 итераций, 124.91 сек\n","Среднее значение функции потерь на обучении 0.017352052387044143\n","Среднее значение функции потерь на валидации 0.016261162854140938\n","\n","Эпоха 7\n","Эпоха: 384 итераций, 124.90 сек\n","Среднее значение функции потерь на обучении 0.01658727460016962\n","Среднее значение функции потерь на валидации 0.014281561487529537\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 384 итераций, 124.90 сек\n","Среднее значение функции потерь на обучении 0.016202881878901582\n","Среднее значение функции потерь на валидации 0.014896898857769694\n","\n","Эпоха 9\n","Эпоха: 384 итераций, 124.91 сек\n","Среднее значение функции потерь на обучении 0.015666251749886822\n","Среднее значение функции потерь на валидации 0.013874152052852482\n","Новая лучшая модель!\n","\n"]}],"source":["(best_val_loss,\n"," best_sentence_level_model) = train_eval_loop(\n","    sentence_level_model,\n","    train_dataset,\n","    test_dataset,\n","    F.cross_entropy,\n","    lr=5e-3,\n","    epoch_n=10,\n","    batch_size=64,\n","    device='cuda',\n","    early_stopping_patience=5,\n","    max_batches_per_epoch_train=500,\n","    max_batches_per_epoch_val=100,\n","    lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optim, patience=2,\n","        factor=0.5,\n","        verbose=True\n","    )\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:16.542052Z","start_time":"2019-08-29T13:56:16.529110Z"},"execution":{"iopub.execute_input":"2024-09-19T15:53:47.250735Z","iopub.status.busy":"2024-09-19T15:53:47.249850Z","iopub.status.idle":"2024-09-19T15:53:47.310788Z","shell.execute_reply":"2024-09-19T15:53:47.309721Z","shell.execute_reply.started":"2024-09-19T15:53:47.250693Z"},"trusted":true},"outputs":[],"source":["torch.save(best_sentence_level_model.state_dict(), './stepik-dl-nlp/models/sentence_level_pos.pth')"]},{"cell_type":"code","execution_count":30,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:16.564926Z","start_time":"2019-08-29T13:56:16.544481Z"},"execution":{"iopub.execute_input":"2024-09-19T15:54:14.889983Z","iopub.status.busy":"2024-09-19T15:54:14.889606Z","iopub.status.idle":"2024-09-19T15:54:14.955564Z","shell.execute_reply":"2024-09-19T15:54:14.954572Z","shell.execute_reply.started":"2024-09-19T15:54:14.889950Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["sentence_level_model.load_state_dict(torch.load('./stepik-dl-nlp/models/sentence_level_pos.pth', weights_only=True))"]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.092139Z","start_time":"2019-08-29T13:56:16.567242Z"},"execution":{"iopub.execute_input":"2024-09-19T15:54:18.298923Z","iopub.status.busy":"2024-09-19T15:54:18.298062Z","iopub.status.idle":"2024-09-19T15:54:54.839956Z","shell.execute_reply":"2024-09-19T15:54:54.838890Z","shell.execute_reply.started":"2024-09-19T15:54:18.298882Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["767it [00:10, 73.50it/s]                             \n","/tmp/ipykernel_36/4087871673.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(train_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.011324310675263405\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   4330443\n","         ADJ       0.90      0.95      0.93     43357\n","         ADP       1.00      0.99      1.00     39344\n","         ADV       0.91      0.92      0.92     22733\n","         AUX       0.85      0.95      0.90      3537\n","       CCONJ       0.94      0.98      0.96     15168\n","         DET       0.91      0.92      0.91     10781\n","        INTJ       1.00      0.22      0.36        50\n","        NOUN       0.98      0.96      0.97    103538\n","         NUM       0.94      0.93      0.93      5640\n","        PART       0.97      0.86      0.91     13556\n","        PRON       0.94      0.91      0.93     18734\n","       PROPN       0.96      0.94      0.95     14854\n","       PUNCT       1.00      1.00      1.00     77972\n","       SCONJ       0.87      0.95      0.91      8057\n","         SYM       0.99      1.00      1.00       420\n","        VERB       0.94      0.96      0.95     47731\n","           X       0.95      0.67      0.79       189\n","\n","    accuracy                           1.00   4756104\n","   macro avg       0.95      0.89      0.91   4756104\n","weighted avg       1.00      1.00      1.00   4756104\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["279it [00:03, 73.63it/s]                              \n","/tmp/ipykernel_36/4087871673.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(test_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.016288768500089645\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1574439\n","         ADJ       0.88      0.93      0.91     15103\n","         ADP       0.99      0.99      0.99     13717\n","         ADV       0.88      0.90      0.89      7783\n","         AUX       0.87      0.93      0.90      1390\n","       CCONJ       0.94      0.98      0.96      5672\n","         DET       0.90      0.86      0.88      4265\n","        INTJ       1.00      0.25      0.40        24\n","        NOUN       0.97      0.95      0.96     36238\n","         NUM       0.89      0.87      0.88      1734\n","        PART       0.97      0.84      0.90      5125\n","        PRON       0.93      0.91      0.92      7444\n","       PROPN       0.93      0.91      0.92      5473\n","       PUNCT       1.00      1.00      1.00     29186\n","       SCONJ       0.85      0.94      0.89      2865\n","         SYM       0.95      0.92      0.93        62\n","        VERB       0.93      0.95      0.94     17110\n","           X       0.89      0.62      0.73       134\n","\n","    accuracy                           1.00   1727764\n","   macro avg       0.93      0.88      0.89   1727764\n","weighted avg       1.00      1.00      1.00   1727764\n","\n"]}],"source":["train_pred = predict_with_model(sentence_level_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(sentence_level_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]},{"cell_type":"markdown","metadata":{},"source":["## Применение полученных теггеров и сравнение"]},{"cell_type":"code","execution_count":32,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.105418Z","start_time":"2019-08-29T13:56:42.093744Z"},"execution":{"iopub.execute_input":"2024-09-19T15:56:32.552534Z","iopub.status.busy":"2024-09-19T15:56:32.552113Z","iopub.status.idle":"2024-09-19T15:56:32.608502Z","shell.execute_reply":"2024-09-19T15:56:32.607489Z","shell.execute_reply.started":"2024-09-19T15:56:32.552485Z"},"trusted":true},"outputs":[],"source":["single_token_pos_tagger = POSTagger(\n","    single_token_model, char_vocab, UNIQUE_TAGS,\n","    MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN\n",")\n","sentence_level_pos_tagger = POSTagger(\n","    sentence_level_model, char_vocab, UNIQUE_TAGS,\n","    MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.125540Z","start_time":"2019-08-29T13:56:42.106771Z"},"execution":{"iopub.execute_input":"2024-09-19T15:56:35.914270Z","iopub.status.busy":"2024-09-19T15:56:35.913389Z","iopub.status.idle":"2024-09-19T15:56:35.968040Z","shell.execute_reply":"2024-09-19T15:56:35.967072Z","shell.execute_reply.started":"2024-09-19T15:56:35.914232Z"},"trusted":true},"outputs":[],"source":["test_sentences = [\n","    'Мама мыла раму.',\n","    'Косил косой косой косой.',\n","    'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n","    'Сяпала Калуша с Калушатами по напушке.',\n","    'Пирожки поставлены в печь, мама любит печь.',\n","    'Ведро дало течь, вода стала течь.',\n","    'Три да три, будет дырка.',\n","    'Три да три, будет шесть.',\n","    'Сорок сорок'\n","]\n","test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)"]},{"cell_type":"code","execution_count":34,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.148124Z","start_time":"2019-08-29T13:56:42.126930Z"},"execution":{"iopub.execute_input":"2024-09-19T15:56:39.674671Z","iopub.status.busy":"2024-09-19T15:56:39.673775Z","iopub.status.idle":"2024-09-19T15:56:39.743058Z","shell.execute_reply":"2024-09-19T15:56:39.742094Z","shell.execute_reply.started":"2024-09-19T15:56:39.674631Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00, 148.43it/s]                    "]},{"name":"stdout","output_type":"stream","text":["мама-NOUN мыла-NOUN раму-NOUN\n","\n","косил-VERB косой-ADJ косой-ADJ косой-ADJ\n","\n","глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n","\n","сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-ADV\n","\n","пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN\n","\n","ведро-NOUN дало-VERB течь-VERB вода-NOUN стала-VERB течь-VERB\n","\n","три-NUM да-CCONJ три-NUM будет-AUX дырка-NOUN\n","\n","три-NUM да-CCONJ три-NUM будет-AUX шесть-NUM\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n","    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","    print()"]},{"cell_type":"code","execution_count":35,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.168810Z","start_time":"2019-08-29T13:56:42.149698Z"},"execution":{"iopub.execute_input":"2024-09-19T15:56:45.054490Z","iopub.status.busy":"2024-09-19T15:56:45.053734Z","iopub.status.idle":"2024-09-19T15:56:45.121562Z","shell.execute_reply":"2024-09-19T15:56:45.120596Z","shell.execute_reply.started":"2024-09-19T15:56:45.054452Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00, 175.20it/s]                    "]},{"name":"stdout","output_type":"stream","text":["мама-NOUN мыла-VERB раму-NOUN\n","\n","косил-VERB косой-ADJ косой-ADJ косой-NOUN\n","\n","глокая-ADJ куздра-NOUN штеко-ADJ будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n","\n","сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n","\n","пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN\n","\n","ведро-ADV дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN\n","\n","три-NUM да-NOUN три-NUM будет-AUX дырка-NOUN\n","\n","три-NUM да-NOUN три-NUM будет-AUX шесть-VERB\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n","    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["## Свёрточный модуль своими руками"]},{"cell_type":"code","execution_count":36,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.193140Z","start_time":"2019-08-29T13:56:42.170233Z"},"execution":{"iopub.execute_input":"2024-09-19T15:59:32.317205Z","iopub.status.busy":"2024-09-19T15:59:32.316315Z","iopub.status.idle":"2024-09-19T15:59:32.377119Z","shell.execute_reply":"2024-09-19T15:59:32.376037Z","shell.execute_reply.started":"2024-09-19T15:59:32.317166Z"},"trusted":true},"outputs":[],"source":["class MyConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.weight = nn.Parameter(\n","            torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n","            requires_grad=True)\n","        self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n","    \n","    def forward(self, x):\n","        \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n","\n","        batch_size, src_channels, sequence_len = x.shape        \n","        if self.padding > 0:\n","            pad = x.new_zeros(batch_size, src_channels, self.padding)\n","            x = torch.cat((pad, x, pad), dim=-1)\n","            sequence_len = x.shape[-1]\n","\n","        chunks = []\n","        chunk_size = sequence_len - self.kernel_size + 1\n","        for offset in range(self.kernel_size):\n","            chunks.append(x[:, :, offset:offset + chunk_size])\n","\n","        in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n","        in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n","        out_features = torch.bmm(\n","            in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)\n","            ) + self.bias.unsqueeze(0).unsqueeze(0)\n","        out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n","        return out_features"]},{"cell_type":"code","execution_count":38,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.210013Z","start_time":"2019-08-29T13:56:42.194620Z"},"execution":{"iopub.execute_input":"2024-09-19T16:00:22.045718Z","iopub.status.busy":"2024-09-19T16:00:22.045320Z","iopub.status.idle":"2024-09-19T16:00:22.104843Z","shell.execute_reply":"2024-09-19T16:00:22.103821Z","shell.execute_reply.started":"2024-09-19T16:00:22.045681Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 84370\n"]}],"source":["sentence_level_model_my_conv = SentenceLevelPOSTagger(\n","    len(char_vocab), len(label2id), embedding_size=64,\n","    single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n","    context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d)\n",")\n","print(\n","    'Количество параметров',\n","    sum(np.prod(t.shape) for t in sentence_level_model_my_conv.parameters())\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T14:06:00.233326Z","start_time":"2019-08-29T13:56:42.211456Z"},"execution":{"iopub.execute_input":"2024-09-19T16:02:18.717674Z","iopub.status.busy":"2024-09-19T16:02:18.716884Z","iopub.status.idle":"2024-09-19T16:10:12.891462Z","shell.execute_reply":"2024-09-19T16:10:12.890479Z","shell.execute_reply.started":"2024-09-19T16:02:18.717633Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 384 итераций, 43.28 сек\n","Среднее значение функции потерь на обучении 0.08514788059255807\n","Среднее значение функции потерь на валидации 0.02483693977799451\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 384 итераций, 43.22 сек\n","Среднее значение функции потерь на обучении 0.023865993692500826\n","Среднее значение функции потерь на валидации 0.020364512311350003\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 384 итераций, 43.17 сек\n","Среднее значение функции потерь на обучении 0.020264710520374745\n","Среднее значение функции потерь на валидации 0.01702585384839832\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 384 итераций, 43.18 сек\n","Среднее значение функции потерь на обучении 0.018358689795907896\n","Среднее значение функции потерь на валидации 0.01579124671360939\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 384 итераций, 43.17 сек\n","Среднее значение функции потерь на обучении 0.0174412473133998\n","Среднее значение функции потерь на валидации 0.015628617339868946\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 384 итераций, 43.17 сек\n","Среднее значение функции потерь на обучении 0.016442632314768463\n","Среднее значение функции потерь на валидации 0.015422317462207952\n","Новая лучшая модель!\n","\n","Эпоха 6\n","Эпоха: 384 итераций, 43.18 сек\n","Среднее значение функции потерь на обучении 0.01592060432206684\n","Среднее значение функции потерь на валидации 0.013661031353075316\n","Новая лучшая модель!\n","\n","Эпоха 7\n","Эпоха: 384 итераций, 43.17 сек\n","Среднее значение функции потерь на обучении 0.015739236541170005\n","Среднее значение функции потерь на валидации 0.014019956803041519\n","\n","Эпоха 8\n","Эпоха: 384 итераций, 43.17 сек\n","Среднее значение функции потерь на обучении 0.015120190235999567\n","Среднее значение функции потерь на валидации 0.013493308138176062\n","Новая лучшая модель!\n","\n","Эпоха 9\n","Эпоха: 384 итераций, 43.18 сек\n","Среднее значение функции потерь на обучении 0.014884767871990334\n","Среднее значение функции потерь на валидации 0.012748778138383486\n","Новая лучшая модель!\n","\n"]}],"source":["(best_val_loss,\n"," best_sentence_level_model_my_conv) = train_eval_loop(\n","    sentence_level_model_my_conv,\n","    train_dataset,\n","    test_dataset,\n","    F.cross_entropy,\n","    lr=5e-3,\n","    epoch_n=10,\n","    batch_size=64,\n","    device='cuda',\n","    early_stopping_patience=5,\n","    max_batches_per_epoch_train=500,\n","    max_batches_per_epoch_val=100,\n","    lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optim, patience=2, factor=0.5, verbose=True\n","    )\n",")"]},{"cell_type":"code","execution_count":40,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T14:06:39.145214Z","start_time":"2019-08-29T14:06:00.234936Z"},"execution":{"iopub.execute_input":"2024-09-19T16:12:08.479283Z","iopub.status.busy":"2024-09-19T16:12:08.478298Z","iopub.status.idle":"2024-09-19T16:12:51.292150Z","shell.execute_reply":"2024-09-19T16:12:51.291142Z","shell.execute_reply.started":"2024-09-19T16:12:08.479234Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["767it [00:15, 48.13it/s]                             \n","/tmp/ipykernel_36/2860330095.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(train_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.010340110398828983\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   4330443\n","         ADJ       0.95      0.93      0.94     43357\n","         ADP       1.00      0.99      0.99     39344\n","         ADV       0.89      0.94      0.91     22733\n","         AUX       0.88      0.93      0.90      3537\n","       CCONJ       0.96      0.96      0.96     15168\n","         DET       0.90      0.93      0.92     10781\n","        INTJ       0.80      0.24      0.37        50\n","        NOUN       0.97      0.97      0.97    103538\n","         NUM       0.94      0.96      0.95      5640\n","        PART       0.96      0.88      0.92     13556\n","        PRON       0.96      0.92      0.94     18734\n","       PROPN       0.93      0.97      0.95     14854\n","       PUNCT       1.00      1.00      1.00     77972\n","       SCONJ       0.88      0.87      0.87      8057\n","         SYM       1.00      1.00      1.00       420\n","        VERB       0.95      0.97      0.96     47731\n","           X       0.94      0.69      0.79       189\n","\n","    accuracy                           1.00   4756104\n","   macro avg       0.94      0.90      0.91   4756104\n","weighted avg       1.00      1.00      1.00   4756104\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["279it [00:05, 48.52it/s]                              \n","/tmp/ipykernel_36/2860330095.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(test_labels))\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.015042448416352272\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1574439\n","         ADJ       0.93      0.90      0.92     15103\n","         ADP       0.99      0.99      0.99     13717\n","         ADV       0.86      0.92      0.89      7783\n","         AUX       0.88      0.92      0.90      1390\n","       CCONJ       0.96      0.96      0.96      5672\n","         DET       0.89      0.88      0.89      4265\n","        INTJ       0.73      0.33      0.46        24\n","        NOUN       0.96      0.96      0.96     36238\n","         NUM       0.90      0.90      0.90      1734\n","        PART       0.95      0.85      0.90      5125\n","        PRON       0.95      0.91      0.93      7444\n","       PROPN       0.89      0.95      0.92      5473\n","       PUNCT       1.00      1.00      1.00     29186\n","       SCONJ       0.87      0.87      0.87      2865\n","         SYM       0.93      0.90      0.92        62\n","        VERB       0.93      0.96      0.95     17110\n","           X       0.88      0.72      0.80       134\n","\n","    accuracy                           1.00   1727764\n","   macro avg       0.92      0.89      0.90   1727764\n","weighted avg       1.00      1.00      1.00   1727764\n","\n"]}],"source":["train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":4}
